Warning: Flow failed to import. Set the environment variable D4RL_SUPPRESS_IMPORT_ERROR=1 to suppress this message.
No module named 'flow'
INFO:absl:MUJOCO_GL is not set, so an OpenGL backend will be chosen automatically.
/home-nfs/doctorduality/mc3/envs/ml2/lib/python3.9/site-packages/glfw/__init__.py:906: GLFWError: (65544) b'X11: The DISPLAY environment variable is missing'
  warnings.warn(message, GLFWError)
INFO:absl:Successfully imported OpenGL backend: glfw
INFO:absl:MuJoCo library version is: 210
Warning: CARLA failed to import. Set the environment variable D4RL_SUPPRESS_IMPORT_ERROR=1 to suppress this message.
No module named 'carla'
pybullet build time: Dec  1 2021 18:34:28
/home-nfs/doctorduality/mc3/envs/ml2/lib/python3.9/site-packages/gym/spaces/box.py:73: UserWarning: [33mWARN: Box bound precision lowered by casting to float32[0m
  logger.warn(
/share/data/mei-work/jolly/decision_transformers/sql/evaluation/DTevaluation.py:52: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1639180487213/work/torch/csrc/utils/tensor_new.cpp:201.)
  s = torch.tensor([env.reset()], dtype=self.dtype, device=self.device)
/share/data/mei-work/jolly/decision_transformers/sql/evaluation/DTevaluation.py:71: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  a = torch.cat((a, torch.tensor(action, dtype=self.dtype, device=self.device).reshape(1, -1)))
JJ DT Experiment with 10000 training steps, 0.0001 learning rate, 10000 warmup steps, and start seed 1
==================================================
Starting new experiment: hopper medium-replay
2041 trajectories, 402000 timesteps found
Average return: 467.30, std: 511.03
Max return: 3192.93, min: -1.44
==================================================
==================================================
Iteration with seed 1
Train
Training time:  807.5905134677887
Training time per batch:  0.08075905134677887
BM Evaluate
{'target_3600_return_mean': 1487.7804098169488, 'target_3600_return_std': 188.44171977168506, 'target_3600_length_mean': 458.62, 'target_3600_length_std': 60.6352669656859}
evaluation time:  175.53446316719055
mean return 1487.7804098169488
std returns 188.44171977168506
mean lengths 458.62
std lengths 60.6352669656859
1487.7804098169488,188.44171977168506,458.62,60.6352669656859,1
Evaluate
evaluation time:  38.88433599472046
mean return 7.26546510639372
std returns 0.03562756075012204
mean lengths 100.14
std lengths 0.7351190379795641
7.26546510639372,0.03562756075012204,100.14,0.7351190379795641,1
==================================================
Starting new experiment: hopper medium-replay
2041 trajectories, 402000 timesteps found
Average return: 467.30, std: 511.03
Max return: 3192.93, min: -1.44
==================================================
==================================================
Iteration with seed 2
Train
Training time:  803.4782087802887
Training time per batch:  0.08034782087802887
BM Evaluate
{'target_3600_return_mean': 849.9121622510714, 'target_3600_return_std': 128.48404542550796, 'target_3600_length_mean': 258.26, 'target_3600_length_std': 37.47415642813058}
evaluation time:  100.66718053817749
mean return 849.9121622510714
std returns 128.48404542550796
mean lengths 258.26
std lengths 37.47415642813058
849.9121622510714,128.48404542550796,258.26,37.47415642813058,1
Evaluate
evaluation time:  40.16883611679077
mean return 7.351478342800327
std returns 0.10647856135711124
mean lengths 99.58
std lengths 2.298608274587038
7.351478342800327,0.10647856135711124,99.58,2.298608274587038,1
==================================================
Starting new experiment: hopper medium-replay
2041 trajectories, 402000 timesteps found
Average return: 467.30, std: 511.03
Max return: 3192.93, min: -1.44
==================================================
==================================================
Iteration with seed 3
Train
Training time:  805.7048087120056
Training time per batch:  0.08057048087120056
BM Evaluate
{'target_3600_return_mean': 1884.8064814257202, 'target_3600_return_std': 382.44602998181443, 'target_3600_length_mean': 612.96, 'target_3600_length_std': 126.25513217291407}
evaluation time:  238.09560322761536
mean return 1884.8064814257202
std returns 382.44602998181443
mean lengths 612.96
std lengths 126.25513217291407
1884.8064814257202,382.44602998181443,612.96,126.25513217291407,1
Evaluate
evaluation time:  384.79158782958984
mean return 68.84757454203617
std returns 1.5963864423821554
mean lengths 1000.0
std lengths 0.0
68.84757454203617,1.5963864423821554,1000.0,0.0,1
==================================================
Starting new experiment: hopper medium-replay
2041 trajectories, 402000 timesteps found
Average return: 467.30, std: 511.03
Max return: 3192.93, min: -1.44
==================================================
==================================================
Iteration with seed 4
Train
Training time:  804.65314245224
Training time per batch:  0.080465314245224
BM Evaluate
{'target_3600_return_mean': 522.2610441777244, 'target_3600_return_std': 49.838760130800075, 'target_3600_length_mean': 250.18, 'target_3600_length_std': 14.752206614605152}
evaluation time:  100.05614829063416
mean return 522.2610441777244
std returns 49.838760130800075
mean lengths 250.18
std lengths 14.752206614605152
522.2610441777244,49.838760130800075,250.18,14.752206614605152,1
Evaluate
evaluation time:  27.928853750228882
mean return 4.041230774368989
std returns 0.04440053118578614
mean lengths 71.69
std lengths 1.8798670165732465
4.041230774368989,0.04440053118578614,71.69,1.8798670165732465,1
==================================================
Starting new experiment: hopper medium-replay
2041 trajectories, 402000 timesteps found
Average return: 467.30, std: 511.03
Max return: 3192.93, min: -1.44
==================================================
==================================================
Iteration with seed 5
Train
Training time:  799.5148384571075
Training time per batch:  0.07995148384571076
BM Evaluate
{'target_3600_return_mean': 691.3620764991323, 'target_3600_return_std': 107.5526152052417, 'target_3600_length_mean': 238.55, 'target_3600_length_std': 29.26819946631497}
evaluation time:  93.45532846450806
mean return 691.3620764991323
std returns 107.5526152052417
mean lengths 238.55
std lengths 29.26819946631497
691.3620764991323,107.5526152052417,238.55,29.26819946631497,1
Evaluate
evaluation time:  43.222336292266846
mean return 7.6202003813841905
std returns 0.09526971706159193
mean lengths 111.88
std lengths 2.4506325713986588
7.6202003813841905,0.09526971706159193,111.88,2.4506325713986588,1
==================================================
Starting new experiment: hopper medium-replay
2041 trajectories, 402000 timesteps found
Average return: 467.30, std: 511.03
Max return: 3192.93, min: -1.44
==================================================
==================================================
Iteration with seed 6
Train
Training time:  798.2786560058594
Training time per batch:  0.07982786560058594
BM Evaluate
{'target_3600_return_mean': 872.8449612524516, 'target_3600_return_std': 186.7491624068493, 'target_3600_length_mean': 298.82, 'target_3600_length_std': 43.84983010229344}
evaluation time:  115.07590436935425
mean return 872.8449612524516
std returns 186.7491624068493
mean lengths 298.82
std lengths 43.84983010229344
872.8449612524516,186.7491624068493,298.82,43.84983010229344,1
Evaluate
evaluation time:  65.88259053230286
mean return 9.495171849938593
std returns 0.1410617547603809
mean lengths 170.37
std lengths 4.09305509369224
9.495171849938593,0.1410617547603809,170.37,4.09305509369224,1
==================================================
Starting new experiment: hopper medium-replay
2041 trajectories, 402000 timesteps found
Average return: 467.30, std: 511.03
Max return: 3192.93, min: -1.44
==================================================
==================================================
Iteration with seed 7
Train
Training time:  799.5166554450989
Training time per batch:  0.07995166554450989
BM Evaluate
{'target_3600_return_mean': 450.2774297309536, 'target_3600_return_std': 98.64910885475325, 'target_3600_length_mean': 165.4, 'target_3600_length_std': 24.850352110181458}
evaluation time:  63.89159917831421
mean return 450.2774297309536
std returns 98.64910885475325
mean lengths 165.4
std lengths 24.850352110181458
450.2774297309536,98.64910885475325,165.4,24.850352110181458,1
Evaluate
evaluation time:  38.47091722488403
mean return 7.247995358560393
std returns 0.09580291907596594
mean lengths 98.97
std lengths 2.5747038664669772
7.247995358560393,0.09580291907596594,98.97,2.5747038664669772,1
==================================================
Starting new experiment: hopper medium-replay
2041 trajectories, 402000 timesteps found
Average return: 467.30, std: 511.03
Max return: 3192.93, min: -1.44
==================================================
==================================================
Iteration with seed 8
Train
Training time:  801.2092716693878
Training time per batch:  0.08012092716693878
BM Evaluate
{'target_3600_return_mean': 699.6772228067471, 'target_3600_return_std': 42.66520959597089, 'target_3600_length_mean': 223.25, 'target_3600_length_std': 9.04032632154393}
evaluation time:  86.62061333656311
mean return 699.6772228067471
std returns 42.66520959597089
mean lengths 223.25
std lengths 9.04032632154393
699.6772228067471,42.66520959597089,223.25,9.04032632154393,1
Evaluate
evaluation time:  62.71272659301758
mean return 12.833520253459339
std returns 0.2112243728687901
mean lengths 160.7
std lengths 3.451086785347479
12.833520253459339,0.2112243728687901,160.7,3.451086785347479,1
==================================================
Starting new experiment: hopper medium-replay
2041 trajectories, 402000 timesteps found
Average return: 467.30, std: 511.03
Max return: 3192.93, min: -1.44
==================================================
==================================================
Iteration with seed 9
Train
Training time:  797.5408864021301
Training time per batch:  0.07975408864021301
BM Evaluate
{'target_3600_return_mean': 1523.9603793587107, 'target_3600_return_std': 469.1730486445941, 'target_3600_length_mean': 477.02, 'target_3600_length_std': 155.65223930287672}
evaluation time:  184.19142127037048
mean return 1523.9603793587107
std returns 469.1730486445941
mean lengths 477.02
std lengths 155.65223930287672
1523.9603793587107,469.1730486445941,477.02,155.65223930287672,1
Evaluate
evaluation time:  35.56941556930542
mean return 6.956199419544176
std returns 0.12202687647185577
mean lengths 91.98
std lengths 1.4211263138792414
6.956199419544176,0.12202687647185577,91.98,1.4211263138792414,1
==================================================
Starting new experiment: hopper medium-replay
2041 trajectories, 402000 timesteps found
Average return: 467.30, std: 511.03
Max return: 3192.93, min: -1.44
==================================================
==================================================
Iteration with seed 10
Train
Training time:  810.2325060367584
Training time per batch:  0.08102325060367584
BM Evaluate
{'target_3600_return_mean': 589.7696997782757, 'target_3600_return_std': 151.96489097701098, 'target_3600_length_mean': 176.59, 'target_3600_length_std': 40.37724482923519}
evaluation time:  76.1227674484253
mean return 589.7696997782757
std returns 151.96489097701098
mean lengths 176.59
std lengths 40.37724482923519
589.7696997782757,151.96489097701098,176.59,40.37724482923519,1
Evaluate
evaluation time:  50.84058332443237
mean return 10.23872158089812
std returns 3.4583909104064103
mean lengths 128.13
std lengths 27.897904939260222
10.23872158089812,3.4583909104064103,128.13,27.897904939260222,1
