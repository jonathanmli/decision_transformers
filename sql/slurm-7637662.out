Warning: Flow failed to import. Set the environment variable D4RL_SUPPRESS_IMPORT_ERROR=1 to suppress this message.
No module named 'flow'
INFO:absl:MUJOCO_GL is not set, so an OpenGL backend will be chosen automatically.
/home-nfs/doctorduality/mc3/envs/ml2/lib/python3.9/site-packages/glfw/__init__.py:906: GLFWError: (65544) b'X11: The DISPLAY environment variable is missing'
  warnings.warn(message, GLFWError)
INFO:absl:Successfully imported OpenGL backend: glfw
INFO:absl:MuJoCo library version is: 210
Warning: CARLA failed to import. Set the environment variable D4RL_SUPPRESS_IMPORT_ERROR=1 to suppress this message.
No module named 'carla'
pybullet build time: Dec  1 2021 18:34:28
/home-nfs/doctorduality/mc3/envs/ml2/lib/python3.9/site-packages/gym/spaces/box.py:73: UserWarning: [33mWARN: Box bound precision lowered by casting to float32[0m
  logger.warn(
/share/data/mei-work/jolly/decision_transformers/sql/evaluation/DTevaluation.py:52: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1639180487213/work/torch/csrc/utils/tensor_new.cpp:201.)
  s = torch.tensor([env.reset()], dtype=self.dtype, device=self.device)
/share/data/mei-work/jolly/decision_transformers/sql/evaluation/DTevaluation.py:71: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  a = torch.cat((a, torch.tensor(action, dtype=self.dtype, device=self.device).reshape(1, -1)))
JJ DT Experiment with 10000 training steps, 0.0001 learning rate, 10000 warmup steps, and start seed 1
==================================================
Starting new experiment: halfcheetah medium
1000 trajectories, 1000000 timesteps found
Average return: 4770.33, std: 355.75
Max return: 5309.38, min: -310.23
==================================================
==================================================
Iteration with seed 1
Train
Training time:  1502.8121273517609
Training time per batch:  0.15028121273517608
BM Evaluate
{'target_6000_return_mean': 4980.807356584653, 'target_6000_return_std': 158.90614655489372, 'target_6000_length_mean': 1000.0, 'target_6000_length_std': 0.0}
evaluation time:  422.15711784362793
mean return 4980.807356584653
std returns 158.90614655489372
mean lengths 1000.0
std lengths 0.0
4980.807356584653,158.90614655489372,1000.0,0.0,1
Evaluate
evaluation time:  425.1139786243439
mean return 41.9708448927069
std returns 6.245558485814631
mean lengths 1000.0
std lengths 0.0
41.9708448927069,6.245558485814631,1000.0,0.0,1
==================================================
Starting new experiment: halfcheetah medium
1000 trajectories, 1000000 timesteps found
Average return: 4770.33, std: 355.75
Max return: 5309.38, min: -310.23
==================================================
==================================================
Iteration with seed 2
Train
Training time:  1521.8148374557495
Training time per batch:  0.15218148374557494
BM Evaluate
{'target_6000_return_mean': 4927.002494650796, 'target_6000_return_std': 494.75865513971655, 'target_6000_length_mean': 1000.0, 'target_6000_length_std': 0.0}
evaluation time:  420.31758546829224
mean return 4927.002494650796
std returns 494.75865513971655
mean lengths 1000.0
std lengths 0.0
4927.002494650796,494.75865513971655,1000.0,0.0,1
Evaluate
evaluation time:  418.6965982913971
mean return 40.36781950232056
std returns 5.5418428702744205
mean lengths 1000.0
std lengths 0.0
40.36781950232056,5.5418428702744205,1000.0,0.0,1
==================================================
Starting new experiment: halfcheetah medium
1000 trajectories, 1000000 timesteps found
Average return: 4770.33, std: 355.75
Max return: 5309.38, min: -310.23
==================================================
==================================================
Iteration with seed 3
Train
Training time:  1684.676724433899
Training time per batch:  0.1684676724433899
BM Evaluate
{'target_6000_return_mean': 4691.54030133832, 'target_6000_return_std': 912.530150780232, 'target_6000_length_mean': 1000.0, 'target_6000_length_std': 0.0}
evaluation time:  481.5803380012512
mean return 4691.54030133832
std returns 912.530150780232
mean lengths 1000.0
std lengths 0.0
4691.54030133832,912.530150780232,1000.0,0.0,1
Evaluate
evaluation time:  482.2251501083374
mean return 40.7623365590325
std returns 4.495906350744131
mean lengths 1000.0
std lengths 0.0
40.7623365590325,4.495906350744131,1000.0,0.0,1
==================================================
Starting new experiment: halfcheetah medium
1000 trajectories, 1000000 timesteps found
Average return: 4770.33, std: 355.75
Max return: 5309.38, min: -310.23
==================================================
==================================================
Iteration with seed 4
Train
Training time:  1713.8474400043488
Training time per batch:  0.17138474400043488
BM Evaluate
{'target_6000_return_mean': 4879.218083644015, 'target_6000_return_std': 645.6110173857659, 'target_6000_length_mean': 1000.0, 'target_6000_length_std': 0.0}
evaluation time:  470.862144947052
mean return 4879.218083644015
std returns 645.6110173857659
mean lengths 1000.0
std lengths 0.0
4879.218083644015,645.6110173857659,1000.0,0.0,1
Evaluate
evaluation time:  472.66437673568726
mean return 41.762308440462384
std returns 2.820395507477211
mean lengths 1000.0
std lengths 0.0
41.762308440462384,2.820395507477211,1000.0,0.0,1
==================================================
Starting new experiment: halfcheetah medium
1000 trajectories, 1000000 timesteps found
Average return: 4770.33, std: 355.75
Max return: 5309.38, min: -310.23
==================================================
==================================================
Iteration with seed 5
Train
Training time:  1718.2224414348602
Training time per batch:  0.171822244143486
BM Evaluate
{'target_6000_return_mean': 4865.377661424722, 'target_6000_return_std': 806.4025118220361, 'target_6000_length_mean': 1000.0, 'target_6000_length_std': 0.0}
evaluation time:  475.8524537086487
mean return 4865.377661424722
std returns 806.4025118220361
mean lengths 1000.0
std lengths 0.0
4865.377661424722,806.4025118220361,1000.0,0.0,1
Evaluate
evaluation time:  473.4274311065674
mean return 42.31277410457042
std returns 0.822782836055174
mean lengths 1000.0
std lengths 0.0
42.31277410457042,0.822782836055174,1000.0,0.0,1
