Warning: Flow failed to import. Set the environment variable D4RL_SUPPRESS_IMPORT_ERROR=1 to suppress this message.
No module named 'flow'
INFO:absl:MUJOCO_GL is not set, so an OpenGL backend will be chosen automatically.
/home-nfs/doctorduality/mc3/envs/ml2/lib/python3.9/site-packages/glfw/__init__.py:906: GLFWError: (65544) b'X11: The DISPLAY environment variable is missing'
  warnings.warn(message, GLFWError)
INFO:absl:Successfully imported OpenGL backend: glfw
INFO:absl:MuJoCo library version is: 210
Warning: CARLA failed to import. Set the environment variable D4RL_SUPPRESS_IMPORT_ERROR=1 to suppress this message.
No module named 'carla'
pybullet build time: Dec  1 2021 18:34:28
/home-nfs/doctorduality/mc3/envs/ml2/lib/python3.9/site-packages/gym/spaces/box.py:73: UserWarning: [33mWARN: Box bound precision lowered by casting to float32[0m
  logger.warn(
/share/data/mei-work/jolly/decision_transformers/sql/evaluation/DTevaluation.py:52: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1639180487213/work/torch/csrc/utils/tensor_new.cpp:201.)
  s = torch.tensor([env.reset()], dtype=self.dtype, device=self.device)
/share/data/mei-work/jolly/decision_transformers/sql/evaluation/DTevaluation.py:71: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  a = torch.cat((a, torch.tensor(action, dtype=self.dtype, device=self.device).reshape(1, -1)))
JJ DT Experiment with 10000 training steps, 0.0001 learning rate, 10000 warmup steps, and start seed 6
==================================================
Starting new experiment: walker2d medium-replay
1093 trajectories, 302000 timesteps found
Average return: 682.70, std: 895.96
Max return: 4132.00, min: -50.20
==================================================
==================================================
Iteration with seed 6
Train
Training time:  1161.186178445816
Training time per batch:  0.1161186178445816
BM Evaluate
{'target_5000_return_mean': 282.38445119162895, 'target_5000_return_std': 464.37553701246054, 'target_5000_length_mean': 263.68, 'target_5000_length_std': 233.13737924236858}
evaluation time:  121.13125777244568
mean return 282.38445119162895
std returns 464.37553701246054
mean lengths 263.68
std lengths 233.13737924236858
282.38445119162895,464.37553701246054,263.68,233.13737924236858,6
Evaluate
evaluation time:  79.61214089393616
mean return 7.043744990813836
std returns 0.2698089877760672
mean lengths 175.87
std lengths 5.26242339611704
7.043744990813836,0.2698089877760672,175.87,5.26242339611704,6
==================================================
Starting new experiment: walker2d medium-replay
1093 trajectories, 302000 timesteps found
Average return: 682.70, std: 895.96
Max return: 4132.00, min: -50.20
==================================================
==================================================
Iteration with seed 7
Train
Training time:  1182.2712903022766
Training time per batch:  0.11822712903022767
BM Evaluate
{'target_5000_return_mean': 859.927325776099, 'target_5000_return_std': 377.213373608863, 'target_5000_length_mean': 845.81, 'target_5000_length_std': 278.01351388017093}
evaluation time:  379.878968000412
mean return 859.927325776099
std returns 377.213373608863
mean lengths 845.81
std lengths 278.01351388017093
859.927325776099,377.213373608863,845.81,278.01351388017093,6
Evaluate
evaluation time:  107.56735706329346
mean return 2.707637537012655
std returns 2.87705123203769
mean lengths 236.67
std lengths 101.39704680117661
2.707637537012655,2.87705123203769,236.67,101.39704680117661,6
==================================================
Starting new experiment: walker2d medium-replay
1093 trajectories, 302000 timesteps found
Average return: 682.70, std: 895.96
Max return: 4132.00, min: -50.20
==================================================
==================================================
Iteration with seed 8
Train
Training time:  1140.0538358688354
Training time per batch:  0.11400538358688354
BM Evaluate
{'target_5000_return_mean': 551.578709403742, 'target_5000_return_std': 321.12090446046517, 'target_5000_length_mean': 623.97, 'target_5000_length_std': 312.26371723272626}
evaluation time:  289.96042680740356
mean return 551.578709403742
std returns 321.12090446046517
mean lengths 623.97
std lengths 312.26371723272626
551.578709403742,321.12090446046517,623.97,312.26371723272626,6
Evaluate
evaluation time:  404.77392625808716
mean return 18.898041308830205
std returns 4.619587823403851
mean lengths 869.41
std lengths 270.0027442453132
18.898041308830205,4.619587823403851,869.41,270.0027442453132,6
==================================================
Starting new experiment: walker2d medium-replay
1093 trajectories, 302000 timesteps found
Average return: 682.70, std: 895.96
Max return: 4132.00, min: -50.20
==================================================
==================================================
Iteration with seed 9
Train
Training time:  1159.9019865989685
Training time per batch:  0.11599019865989685
BM Evaluate
{'target_5000_return_mean': 913.6011095579478, 'target_5000_return_std': 4.499084270510662, 'target_5000_length_mean': 1000.0, 'target_5000_length_std': 0.0}
evaluation time:  485.86960530281067
mean return 913.6011095579478
std returns 4.499084270510662
mean lengths 1000.0
std lengths 0.0
913.6011095579478,4.499084270510662,1000.0,0.0,6
Evaluate
evaluation time:  100.92549562454224
mean return 7.642382131879283
std returns 5.560133670320053
mean lengths 214.0
std lengths 55.75015695045172
7.642382131879283,5.560133670320053,214.0,55.75015695045172,6
==================================================
Starting new experiment: walker2d medium-replay
1093 trajectories, 302000 timesteps found
Average return: 682.70, std: 895.96
Max return: 4132.00, min: -50.20
==================================================
==================================================
Iteration with seed 10
Train
Training time:  1085.6388812065125
Training time per batch:  0.10856388812065125
BM Evaluate
{'target_5000_return_mean': 2486.7854154757156, 'target_5000_return_std': 1135.9886738766502, 'target_5000_length_mean': 721.89, 'target_5000_length_std': 297.48038237840154}
evaluation time:  345.7775571346283
mean return 2486.7854154757156
std returns 1135.9886738766502
mean lengths 721.89
std lengths 297.48038237840154
2486.7854154757156,1135.9886738766502,721.89,297.48038237840154,6
Evaluate
evaluation time:  62.454835176467896
mean return 8.401610333736482
std returns 2.2011220168878047
mean lengths 144.54
std lengths 26.26039603661757
8.401610333736482,2.2011220168878047,144.54,26.26039603661757,6
