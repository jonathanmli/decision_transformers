{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Transformers Replication Report\n",
    "\n",
    "The following project seeks to replicate the gym results of the following paper:\n",
    "\n",
    "https://arxiv.org/abs/2106.01345\n",
    "\n",
    "The offline RL data, data parsing code, and some model parameters are taken from their github:\n",
    "\n",
    "https://github.com/kzl/decision-transformer\n",
    "\n",
    "This project contains the following files:\n",
    "\n",
    "- `RLagents.py` general framework for RL agents\n",
    "- `jonathans_experiment.py` code for running experiments and sampling from datasets\n",
    "- `DTagents.py` framework for decision transformer agents\n",
    "- `models.py` contains the neural networks used\n",
    "- `data` directory containing the offline RL datasets, which can be obtained by following directions on their github repo or from d4rl\n",
    "\n",
    "In addition, make sure that the pytorch, huggingface, and mujoco libraries are in your environment. Instructions to download them can be found on their corresponding websites.\n",
    "\n",
    "Below are some step by step instructions on how to use these files\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from sql.jonathans_experiment import prepare_experiment\n",
    "from sql.DTagents import *\n",
    "import torch\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "Starting new experiment: hopper medium\n",
      "2186 trajectories, 999906 timesteps found\n",
      "Average return: 1422.06, std: 378.95\n",
      "Max return: 3222.36, min: 315.87\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "# make the experiment environment and dt agent\n",
    "new_batch, env, max_ep_len, scale, env_target, state_mean, state_std = prepare_experiment('gym-experiment', device='cpu')\n",
    "dta = DecisionTransformerAgent(env, scale=scale, target_return=env_target, warmup_steps=100, warmup_method=1, \n",
    "                               lr=0.01, state_mean=state_mean, state_std=state_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training time 48.58893084526062\n"
     ]
    }
   ],
   "source": [
    "# train the agent\n",
    "start_time = time.time()\n",
    "for i in range(100):\n",
    "    s, a, r, d, rtg, timesteps, mask = new_batch(64)\n",
    "    dta.offline_train(s, a, r, d, rtg, timesteps, mask, per_batch=True)\n",
    "print('training time', time.time() - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluation time 24.278470516204834\n",
      "mean return 49.69007607395537\n",
      "std returns 1.8752346636348485\n",
      "mean lengths 49.69007607395537\n",
      "std lengths 1.8752346636348485\n"
     ]
    }
   ],
   "source": [
    "# evaluate the agent and compute statistics\n",
    "start_time = time.time()\n",
    "returns, lengths = dta.online_evaluate(100)\n",
    "print('evaluation time', time.time() - start_time)\n",
    "print('mean return', returns.mean())\n",
    "print('std returns', returns.std())\n",
    "print('mean lengths', returns.mean())\n",
    "print('std lengths', returns.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'target_3600_return_mean': 63.37425210199192, 'target_3600_return_std': 1.8183312052112475, 'target_3600_length_mean': 82.0, 'target_3600_length_std': 5.92452529743945}\n",
      "evaluation time 26.04992365837097\n"
     ]
    }
   ],
   "source": [
    "# evaluate the agent using their evaluation code and compute statistics\n",
    "# state_mean\n",
    "from sql.evaluation.DTevaluation import BM_Evaluater\n",
    "start_time = time.time()\n",
    "eva = BM_Evaluater()\n",
    "print(eva.evaluate(dta.env, dta.model))\n",
    "# dta.bm_online_evaluate(10)\n",
    "print('evaluation time', time.time() - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Torch not compiled with CUDA enabled",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_32333/1924372318.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msql\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDTevaluation\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDT_Evaluater\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0meva1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDT_Evaluater\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0meva1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdta\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdta\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'cuda'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/share/data/mei-work/jolly/decision_transformers/sql/evaluation/DTevaluation.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, env, model, dtype, itype, normalized, sequence_length, n_eps, target_return, max_ep_len, scale, device, state_mean, state_std, mode)\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;31m#                 print('eps', i)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m                 \u001b[0;31m# we want to input tensors here\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m                 \u001b[0mR\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtarget_return\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mscale\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m                 \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m                 \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/mc3/envs/ml/lib/python3.9/site-packages/torch/cuda/__init__.py\u001b[0m in \u001b[0;36m_lazy_init\u001b[0;34m()\u001b[0m\n\u001b[1;32m    162\u001b[0m                 \"multiprocessing, you must use the 'spawn' start method\")\n\u001b[1;32m    163\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'_cuda_getDeviceCount'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 164\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mAssertionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Torch not compiled with CUDA enabled\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    165\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_cudart\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m             raise AssertionError(\n",
      "\u001b[0;31mAssertionError\u001b[0m: Torch not compiled with CUDA enabled"
     ]
    }
   ],
   "source": [
    "from sql.evaluation.DTevaluation import DT_Evaluater\n",
    "eva1 = DT_Evaluater()\n",
    "eva1.evaluate(dta.env, dta.model, device='cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "ts shape torch.Size([1])\n",
      "ps emb shape torch.Size([1, 128])\n",
      "torch.Size([1, 128])\n",
      "t sh torch.Size([1])\n",
      "R sh torch.Size([1, 1])\n",
      "torch.Size([2, 11])\n",
      "2\n",
      "ts shape torch.Size([2])\n",
      "ps emb shape torch.Size([2, 128])\n",
      "torch.Size([2, 128])\n",
      "t sh torch.Size([2])\n",
      "R sh torch.Size([2, 1])\n",
      "torch.Size([3, 11])\n",
      "3\n",
      "ts shape torch.Size([3])\n",
      "ps emb shape torch.Size([3, 128])\n",
      "torch.Size([3, 128])\n",
      "t sh torch.Size([3])\n",
      "R sh torch.Size([3, 1])\n",
      "torch.Size([4, 11])\n",
      "4\n",
      "ts shape torch.Size([4])\n",
      "ps emb shape torch.Size([4, 128])\n",
      "torch.Size([4, 128])\n",
      "t sh torch.Size([4])\n",
      "R sh torch.Size([4, 1])\n",
      "torch.Size([5, 11])\n",
      "5\n",
      "ts shape torch.Size([5])\n",
      "ps emb shape torch.Size([5, 128])\n",
      "torch.Size([5, 128])\n",
      "t sh torch.Size([5])\n",
      "R sh torch.Size([5, 1])\n",
      "torch.Size([6, 11])\n",
      "6\n",
      "ts shape torch.Size([6])\n",
      "ps emb shape torch.Size([6, 128])\n",
      "torch.Size([6, 128])\n",
      "t sh torch.Size([6])\n",
      "R sh torch.Size([6, 1])\n",
      "torch.Size([7, 11])\n",
      "7\n",
      "ts shape torch.Size([7])\n",
      "ps emb shape torch.Size([7, 128])\n",
      "torch.Size([7, 128])\n",
      "t sh torch.Size([7])\n",
      "R sh torch.Size([7, 1])\n",
      "torch.Size([8, 11])\n",
      "1\n",
      "ts shape torch.Size([1])\n",
      "ps emb shape torch.Size([1, 128])\n",
      "torch.Size([1, 128])\n",
      "t sh torch.Size([1])\n",
      "R sh torch.Size([1, 1])\n",
      "torch.Size([2, 11])\n",
      "2\n",
      "ts shape torch.Size([2])\n",
      "ps emb shape torch.Size([2, 128])\n",
      "torch.Size([2, 128])\n",
      "t sh torch.Size([2])\n",
      "R sh torch.Size([2, 1])\n",
      "torch.Size([3, 11])\n",
      "3\n",
      "ts shape torch.Size([3])\n",
      "ps emb shape torch.Size([3, 128])\n",
      "torch.Size([3, 128])\n",
      "t sh torch.Size([3])\n",
      "R sh torch.Size([3, 1])\n",
      "torch.Size([4, 11])\n",
      "4\n",
      "ts shape torch.Size([4])\n",
      "ps emb shape torch.Size([4, 128])\n",
      "torch.Size([4, 128])\n",
      "t sh torch.Size([4])\n",
      "R sh torch.Size([4, 1])\n",
      "torch.Size([5, 11])\n",
      "5\n",
      "ts shape torch.Size([5])\n",
      "ps emb shape torch.Size([5, 128])\n",
      "torch.Size([5, 128])\n",
      "t sh torch.Size([5])\n",
      "R sh torch.Size([5, 1])\n",
      "torch.Size([6, 11])\n",
      "6\n",
      "ts shape torch.Size([6])\n",
      "ps emb shape torch.Size([6, 128])\n",
      "torch.Size([6, 128])\n",
      "t sh torch.Size([6])\n",
      "R sh torch.Size([6, 1])\n",
      "torch.Size([7, 11])\n",
      "7\n",
      "ts shape torch.Size([7])\n",
      "ps emb shape torch.Size([7, 128])\n",
      "torch.Size([7, 128])\n",
      "t sh torch.Size([7])\n",
      "R sh torch.Size([7, 1])\n",
      "torch.Size([8, 11])\n",
      "1\n",
      "ts shape torch.Size([1])\n",
      "ps emb shape torch.Size([1, 128])\n",
      "torch.Size([1, 128])\n",
      "t sh torch.Size([1])\n",
      "R sh torch.Size([1, 1])\n",
      "torch.Size([2, 11])\n",
      "2\n",
      "ts shape torch.Size([2])\n",
      "ps emb shape torch.Size([2, 128])\n",
      "torch.Size([2, 128])\n",
      "t sh torch.Size([2])\n",
      "R sh torch.Size([2, 1])\n",
      "torch.Size([3, 11])\n",
      "3\n",
      "ts shape torch.Size([3])\n",
      "ps emb shape torch.Size([3, 128])\n",
      "torch.Size([3, 128])\n",
      "t sh torch.Size([3])\n",
      "R sh torch.Size([3, 1])\n",
      "torch.Size([4, 11])\n",
      "4\n",
      "ts shape torch.Size([4])\n",
      "ps emb shape torch.Size([4, 128])\n",
      "torch.Size([4, 128])\n",
      "t sh torch.Size([4])\n",
      "R sh torch.Size([4, 1])\n",
      "torch.Size([5, 11])\n",
      "5\n",
      "ts shape torch.Size([5])\n",
      "ps emb shape torch.Size([5, 128])\n",
      "torch.Size([5, 128])\n",
      "t sh torch.Size([5])\n",
      "R sh torch.Size([5, 1])\n",
      "torch.Size([6, 11])\n",
      "6\n",
      "ts shape torch.Size([6])\n",
      "ps emb shape torch.Size([6, 128])\n",
      "torch.Size([6, 128])\n",
      "t sh torch.Size([6])\n",
      "R sh torch.Size([6, 1])\n",
      "torch.Size([7, 11])\n",
      "7\n",
      "ts shape torch.Size([7])\n",
      "ps emb shape torch.Size([7, 128])\n",
      "torch.Size([7, 128])\n",
      "t sh torch.Size([7])\n",
      "R sh torch.Size([7, 1])\n",
      "torch.Size([8, 11])\n",
      "1\n",
      "ts shape torch.Size([1])\n",
      "ps emb shape torch.Size([1, 128])\n",
      "torch.Size([1, 128])\n",
      "t sh torch.Size([1])\n",
      "R sh torch.Size([1, 1])\n",
      "torch.Size([2, 11])\n",
      "2\n",
      "ts shape torch.Size([2])\n",
      "ps emb shape torch.Size([2, 128])\n",
      "torch.Size([2, 128])\n",
      "t sh torch.Size([2])\n",
      "R sh torch.Size([2, 1])\n",
      "torch.Size([3, 11])\n",
      "3\n",
      "ts shape torch.Size([3])\n",
      "ps emb shape torch.Size([3, 128])\n",
      "torch.Size([3, 128])\n",
      "t sh torch.Size([3])\n",
      "R sh torch.Size([3, 1])\n",
      "torch.Size([4, 11])\n",
      "4\n",
      "ts shape torch.Size([4])\n",
      "ps emb shape torch.Size([4, 128])\n",
      "torch.Size([4, 128])\n",
      "t sh torch.Size([4])\n",
      "R sh torch.Size([4, 1])\n",
      "torch.Size([5, 11])\n",
      "5\n",
      "ts shape torch.Size([5])\n",
      "ps emb shape torch.Size([5, 128])\n",
      "torch.Size([5, 128])\n",
      "t sh torch.Size([5])\n",
      "R sh torch.Size([5, 1])\n",
      "torch.Size([6, 11])\n",
      "6\n",
      "ts shape torch.Size([6])\n",
      "ps emb shape torch.Size([6, 128])\n",
      "torch.Size([6, 128])\n",
      "t sh torch.Size([6])\n",
      "R sh torch.Size([6, 1])\n",
      "torch.Size([7, 11])\n",
      "7\n",
      "ts shape torch.Size([7])\n",
      "ps emb shape torch.Size([7, 128])\n",
      "torch.Size([7, 128])\n",
      "t sh torch.Size([7])\n",
      "R sh torch.Size([7, 1])\n",
      "torch.Size([8, 11])\n",
      "1\n",
      "ts shape torch.Size([1])\n",
      "ps emb shape torch.Size([1, 128])\n",
      "torch.Size([1, 128])\n",
      "t sh torch.Size([1])\n",
      "R sh torch.Size([1, 1])\n",
      "torch.Size([2, 11])\n",
      "2\n",
      "ts shape torch.Size([2])\n",
      "ps emb shape torch.Size([2, 128])\n",
      "torch.Size([2, 128])\n",
      "t sh torch.Size([2])\n",
      "R sh torch.Size([2, 1])\n",
      "torch.Size([3, 11])\n",
      "3\n",
      "ts shape torch.Size([3])\n",
      "ps emb shape torch.Size([3, 128])\n",
      "torch.Size([3, 128])\n",
      "t sh torch.Size([3])\n",
      "R sh torch.Size([3, 1])\n",
      "torch.Size([4, 11])\n",
      "4\n",
      "ts shape torch.Size([4])\n",
      "ps emb shape torch.Size([4, 128])\n",
      "torch.Size([4, 128])\n",
      "t sh torch.Size([4])\n",
      "R sh torch.Size([4, 1])\n",
      "torch.Size([5, 11])\n",
      "5\n",
      "ts shape torch.Size([5])\n",
      "ps emb shape torch.Size([5, 128])\n",
      "torch.Size([5, 128])\n",
      "t sh torch.Size([5])\n",
      "R sh torch.Size([5, 1])\n",
      "torch.Size([6, 11])\n",
      "6\n",
      "ts shape torch.Size([6])\n",
      "ps emb shape torch.Size([6, 128])\n",
      "torch.Size([6, 128])\n",
      "t sh torch.Size([6])\n",
      "R sh torch.Size([6, 1])\n",
      "torch.Size([7, 11])\n",
      "7\n",
      "ts shape torch.Size([7])\n",
      "ps emb shape torch.Size([7, 128])\n",
      "torch.Size([7, 128])\n",
      "t sh torch.Size([7])\n",
      "R sh torch.Size([7, 1])\n",
      "torch.Size([8, 11])\n",
      "1\n",
      "ts shape torch.Size([1])\n",
      "ps emb shape torch.Size([1, 128])\n",
      "torch.Size([1, 128])\n",
      "t sh torch.Size([1])\n",
      "R sh torch.Size([1, 1])\n",
      "torch.Size([2, 11])\n",
      "2\n",
      "ts shape torch.Size([2])\n",
      "ps emb shape torch.Size([2, 128])\n",
      "torch.Size([2, 128])\n",
      "t sh torch.Size([2])\n",
      "R sh torch.Size([2, 1])\n",
      "torch.Size([3, 11])\n",
      "3\n",
      "ts shape torch.Size([3])\n",
      "ps emb shape torch.Size([3, 128])\n",
      "torch.Size([3, 128])\n",
      "t sh torch.Size([3])\n",
      "R sh torch.Size([3, 1])\n",
      "torch.Size([4, 11])\n",
      "4\n",
      "ts shape torch.Size([4])\n",
      "ps emb shape torch.Size([4, 128])\n",
      "torch.Size([4, 128])\n",
      "t sh torch.Size([4])\n",
      "R sh torch.Size([4, 1])\n",
      "torch.Size([5, 11])\n",
      "5\n",
      "ts shape torch.Size([5])\n",
      "ps emb shape torch.Size([5, 128])\n",
      "torch.Size([5, 128])\n",
      "t sh torch.Size([5])\n",
      "R sh torch.Size([5, 1])\n",
      "torch.Size([6, 11])\n",
      "6\n",
      "ts shape torch.Size([6])\n",
      "ps emb shape torch.Size([6, 128])\n",
      "torch.Size([6, 128])\n",
      "t sh torch.Size([6])\n",
      "R sh torch.Size([6, 1])\n",
      "torch.Size([7, 11])\n",
      "7\n",
      "ts shape torch.Size([7])\n",
      "ps emb shape torch.Size([7, 128])\n",
      "torch.Size([7, 128])\n",
      "t sh torch.Size([7])\n",
      "R sh torch.Size([7, 1])\n",
      "torch.Size([8, 11])\n",
      "1\n",
      "ts shape torch.Size([1])\n",
      "ps emb shape torch.Size([1, 128])\n",
      "torch.Size([1, 128])\n",
      "t sh torch.Size([1])\n",
      "R sh torch.Size([1, 1])\n",
      "torch.Size([2, 11])\n",
      "2\n",
      "ts shape torch.Size([2])\n",
      "ps emb shape torch.Size([2, 128])\n",
      "torch.Size([2, 128])\n",
      "t sh torch.Size([2])\n",
      "R sh torch.Size([2, 1])\n",
      "torch.Size([3, 11])\n",
      "3\n",
      "ts shape torch.Size([3])\n",
      "ps emb shape torch.Size([3, 128])\n",
      "torch.Size([3, 128])\n",
      "t sh torch.Size([3])\n",
      "R sh torch.Size([3, 1])\n",
      "torch.Size([4, 11])\n",
      "4\n",
      "ts shape torch.Size([4])\n",
      "ps emb shape torch.Size([4, 128])\n",
      "torch.Size([4, 128])\n",
      "t sh torch.Size([4])\n",
      "R sh torch.Size([4, 1])\n",
      "torch.Size([5, 11])\n",
      "5\n",
      "ts shape torch.Size([5])\n",
      "ps emb shape torch.Size([5, 128])\n",
      "torch.Size([5, 128])\n",
      "t sh torch.Size([5])\n",
      "R sh torch.Size([5, 1])\n",
      "torch.Size([6, 11])\n",
      "6\n",
      "ts shape torch.Size([6])\n",
      "ps emb shape torch.Size([6, 128])\n",
      "torch.Size([6, 128])\n",
      "t sh torch.Size([6])\n",
      "R sh torch.Size([6, 1])\n",
      "torch.Size([7, 11])\n",
      "7\n",
      "ts shape torch.Size([7])\n",
      "ps emb shape torch.Size([7, 128])\n",
      "torch.Size([7, 128])\n",
      "t sh torch.Size([7])\n",
      "R sh torch.Size([7, 1])\n",
      "torch.Size([8, 11])\n",
      "1\n",
      "ts shape torch.Size([1])\n",
      "ps emb shape torch.Size([1, 128])\n",
      "torch.Size([1, 128])\n",
      "t sh torch.Size([1])\n",
      "R sh torch.Size([1, 1])\n",
      "torch.Size([2, 11])\n",
      "2\n",
      "ts shape torch.Size([2])\n",
      "ps emb shape torch.Size([2, 128])\n",
      "torch.Size([2, 128])\n",
      "t sh torch.Size([2])\n",
      "R sh torch.Size([2, 1])\n",
      "torch.Size([3, 11])\n",
      "3\n",
      "ts shape torch.Size([3])\n",
      "ps emb shape torch.Size([3, 128])\n",
      "torch.Size([3, 128])\n",
      "t sh torch.Size([3])\n",
      "R sh torch.Size([3, 1])\n",
      "torch.Size([4, 11])\n",
      "4\n",
      "ts shape torch.Size([4])\n",
      "ps emb shape torch.Size([4, 128])\n",
      "torch.Size([4, 128])\n",
      "t sh torch.Size([4])\n",
      "R sh torch.Size([4, 1])\n",
      "torch.Size([5, 11])\n",
      "5\n",
      "ts shape torch.Size([5])\n",
      "ps emb shape torch.Size([5, 128])\n",
      "torch.Size([5, 128])\n",
      "t sh torch.Size([5])\n",
      "R sh torch.Size([5, 1])\n",
      "torch.Size([6, 11])\n",
      "6\n",
      "ts shape torch.Size([6])\n",
      "ps emb shape torch.Size([6, 128])\n",
      "torch.Size([6, 128])\n",
      "t sh torch.Size([6])\n",
      "R sh torch.Size([6, 1])\n",
      "torch.Size([7, 11])\n",
      "7\n",
      "ts shape torch.Size([7])\n",
      "ps emb shape torch.Size([7, 128])\n",
      "torch.Size([7, 128])\n",
      "t sh torch.Size([7])\n",
      "R sh torch.Size([7, 1])\n",
      "torch.Size([8, 11])\n",
      "1\n",
      "ts shape torch.Size([1])\n",
      "ps emb shape torch.Size([1, 128])\n",
      "torch.Size([1, 128])\n",
      "t sh torch.Size([1])\n",
      "R sh torch.Size([1, 1])\n",
      "torch.Size([2, 11])\n",
      "2\n",
      "ts shape torch.Size([2])\n",
      "ps emb shape torch.Size([2, 128])\n",
      "torch.Size([2, 128])\n",
      "t sh torch.Size([2])\n",
      "R sh torch.Size([2, 1])\n",
      "torch.Size([3, 11])\n",
      "3\n",
      "ts shape torch.Size([3])\n",
      "ps emb shape torch.Size([3, 128])\n",
      "torch.Size([3, 128])\n",
      "t sh torch.Size([3])\n",
      "R sh torch.Size([3, 1])\n",
      "torch.Size([4, 11])\n",
      "4\n",
      "ts shape torch.Size([4])\n",
      "ps emb shape torch.Size([4, 128])\n",
      "torch.Size([4, 128])\n",
      "t sh torch.Size([4])\n",
      "R sh torch.Size([4, 1])\n",
      "torch.Size([5, 11])\n",
      "5\n",
      "ts shape torch.Size([5])\n",
      "ps emb shape torch.Size([5, 128])\n",
      "torch.Size([5, 128])\n",
      "t sh torch.Size([5])\n",
      "R sh torch.Size([5, 1])\n",
      "torch.Size([6, 11])\n",
      "6\n",
      "ts shape torch.Size([6])\n",
      "ps emb shape torch.Size([6, 128])\n",
      "torch.Size([6, 128])\n",
      "t sh torch.Size([6])\n",
      "R sh torch.Size([6, 1])\n",
      "torch.Size([7, 11])\n",
      "7\n",
      "ts shape torch.Size([7])\n",
      "ps emb shape torch.Size([7, 128])\n",
      "torch.Size([7, 128])\n",
      "t sh torch.Size([7])\n",
      "R sh torch.Size([7, 1])\n",
      "torch.Size([8, 11])\n",
      "1\n",
      "ts shape torch.Size([1])\n",
      "ps emb shape torch.Size([1, 128])\n",
      "torch.Size([1, 128])\n",
      "t sh torch.Size([1])\n",
      "R sh torch.Size([1, 1])\n",
      "torch.Size([2, 11])\n",
      "2\n",
      "ts shape torch.Size([2])\n",
      "ps emb shape torch.Size([2, 128])\n",
      "torch.Size([2, 128])\n",
      "t sh torch.Size([2])\n",
      "R sh torch.Size([2, 1])\n",
      "torch.Size([3, 11])\n",
      "3\n",
      "ts shape torch.Size([3])\n",
      "ps emb shape torch.Size([3, 128])\n",
      "torch.Size([3, 128])\n",
      "t sh torch.Size([3])\n",
      "R sh torch.Size([3, 1])\n",
      "torch.Size([4, 11])\n",
      "4\n",
      "ts shape torch.Size([4])\n",
      "ps emb shape torch.Size([4, 128])\n",
      "torch.Size([4, 128])\n",
      "t sh torch.Size([4])\n",
      "R sh torch.Size([4, 1])\n",
      "torch.Size([5, 11])\n",
      "5\n",
      "ts shape torch.Size([5])\n",
      "ps emb shape torch.Size([5, 128])\n",
      "torch.Size([5, 128])\n",
      "t sh torch.Size([5])\n",
      "R sh torch.Size([5, 1])\n",
      "torch.Size([6, 11])\n",
      "6\n",
      "ts shape torch.Size([6])\n",
      "ps emb shape torch.Size([6, 128])\n",
      "torch.Size([6, 128])\n",
      "t sh torch.Size([6])\n",
      "R sh torch.Size([6, 1])\n",
      "torch.Size([7, 11])\n",
      "7\n",
      "ts shape torch.Size([7])\n",
      "ps emb shape torch.Size([7, 128])\n",
      "torch.Size([7, 128])\n",
      "t sh torch.Size([7])\n",
      "R sh torch.Size([7, 1])\n",
      "torch.Size([8, 11])\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "returns, lengths = dta.online_evaluate(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = torch.tensor([[3,4,5]])\n",
    "t.reshape(-1).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Benchmark \n",
    "For comparison, below are the results after running the experiment using the author's code for 100 iterations with the same parameters\n",
    "\n",
    "- time/training: 41.14713501930237\n",
    "- evaluation/target_3600_return_mean: 42.6457553131806\n",
    "- evaluation/target_3600_return_std: 1.6768748119913417\n",
    "- evaluation/target_3600_length_mean: 27.79\n",
    "- evaluation/target_3600_length_std: 0.8401785524517987\n",
    "\n",
    "- time/total: 63.860310554504395\n",
    "- time/evaluation: 22.713170051574707\n",
    "- training/train_loss_mean: 0.6614395618438721\n",
    "- training/train_loss_std: 0.02305582663767387\n",
    "- training/action_error: 0.6420342326164246\n",
    "\n",
    "Seems like they probably used additional methods than those mentioned in the paper to reduce the variance, but otherwise the results look similiar\n",
    "\n",
    "# Results for larger experiments\n",
    "\n",
    "Below are results when I run the experiment for 1000 iterations with warmup steps = 1000 and lr=0.0001, holding everything else constant\n",
    "- Training time:  408.6037516593933\n",
    "- Training time per batch 0.40860375165939333\n",
    "- mean return 86.40965465081138\n",
    "- std returns 11.182001940365332\n",
    "- mean lengths 86.40965465081138\n",
    "- std lengths 11.182001940365332\n",
    "- Testing time:  24.500950574874878\n",
    "\n",
    "These results are very similiar to those presented in the paper, where they run the experiment for 100000 iterations and 100000 warmup steps instead. However, we do see a higher std than in the results in the paper, as expected with our lower sample size.\n",
    "\n",
    "Unfortunately I did not have the computational resources to run the experiment for 100000 at the current moment, but I expect the results to be similiar. Neither could I run the benchmark for 1000 iterations since it took significantly more computation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notes for further research\n",
    "- The authors do not seem to have normalized their returns per episode using the method from d4rl like they claimed\n",
    "- In their episode evaluation, the authors do not seem to have used scaled returns to go, which was used during training. In our replication we scale the rtg in evaluation\n",
    "- Currently the transformer processes reward to go, state, and action tokens similiarly. I think that using an architecture that differientiates between them would improve performance\n",
    "- Using a better prediction layer than simply single layer linear prediction might result in better action predictions\n",
    "- In evaluation, the unknown next action is currently padded as a zero dimensional vector. This does not indicate to the model that we are trying to predict the unknown rather than translate. I think make modifications on this might be useful\n",
    "- It might be interesting to try to have the model predict future action/state/reward sequences as well in other to create context which can then be used to predict the current action\n",
    "- The loss is currently based on how similiar the predicted actions are to their actual actions. This means that the model is incentivized to stick to existing action sequences, and also that the loss is not based on the reward earned. Having the loss include rewards might incentivize the model to innovate new sequences and thus improve performance\n",
    "- I tried adding more warmup methods but they did not seem to be of great effect\n",
    "\n",
    "I think that these would be interesting improvements to the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
